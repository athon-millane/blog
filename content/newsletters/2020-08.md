---
date: 020-08-14T21:00:39Z
---

Welcome to the August edition of Cloudera Fast Forward's monthly newsletter. Our team have been taking some well-deserved vacation this month, but we have several new research projects underway that we're excited to share with you soon. In the meantime, several of our recent webinars are available to watch on-demand, and our research engineers have some new recommended reading to share.

---

## Our Recent Research

### NLP for Question Answering

What if you could ask your email client, “Who sent me the link with the latest financial report?” Automated question answering is a human-machine interaction to extract information from data using natural language. This general capability can take many forms, but one of the most exciting developments has been question answering from unstructured text data, including the massive amounts of information contained in emails, social media posts, blogs, log files, financial statements -- and the list goes on. Thanks to a series of advances in deep learning techniques in the past two years, question answering capabilities have grown rapidly, and while still emerging, it’s the perfect time to examine how this technology works, when it works well, and where it might still fall short.

- Blog: [NLP for Question Answering](https://qa.fastforwardlabs.com/)
- Prototype: [Neural QA](https://neuralqa.fastforwardlabs.com/)
- Webinar: [Deep Learning for Automated Question Answering](https://www.cloudera.com/about/events/webinars/deep-learning-for-automated-question-answering.html)

### Causality for Machine Learning

Machine learning allows us to detect subtle correlations in large data sets, and use those correlations to make accurate predictions. However, these subtle correlations are often spurious - they exist only in a particular dataset - and the resultant model performs poorly, or gives unexpected results in the real world. Moreover, reasoning based on spurious correlations is dangerous. Business decisions should be based on things that are true, not things that are true only in a limited dataset. The trouble, of course, is identifying what is spurious and what is not. In this report, we explain how combining causal inference with machine learning can help us address these problems.

- Report: [Causality for Machine Learning](https://ff13.fastforwardlabs.com/)
- Prototype: [Scene](http://scene.fastforwardlabs.com/)
- Webinar: [Causality for Machine Learning](https://www.cloudera.com/about/events/webinars/causality-for-machine-learning.html)

### Interpretability

Machine learning (ML) techniques like deep learning can deliver transformative business outcomes, yet the black-box nature of these approaches creates barriers of understanding that can slow adoption to a halt. ML model interpretability, or the ability to explain why and how a model makes a prediction, can enable enterprises to quickly understand predictive outcomes and confidently make decisions that optimize for future business results.

- Report: [Interpretability](https://ff06-2020.fastforwardlabs.com/)
- Prototype: [Refractor](https://refractor.fastforwardlabs.com/)
- Webinar: [Opening the Machine Learning Black Box: Deploying Interpretable Models to Business Users](https://www.cloudera.com/content/dam/www/marketing/resources/webinars/opening-the-machine-learning-black-box.png.landing.html)

---

## Recommended reading

Our research engineers share their favourite reads of the month.

- [Zero-Shot Learning in Modern NLP](https://joeddav.github.io/blog/2020/05/29/ZSL.html)
  One of the hallmarks of large NLP models is their propensity for transfer learning — models trained on massive unsupervised datasets can be leveraged for new tasks by training them further on smaller, supervised training sets. But even these "smaller" datasets are often composed of thousands or tens of thousands of examples, and generating that much labeled data for specific use cases can be costly. This blog post details new techniques that harness powerful NLP models for text classification with few or no labeled training data, known as few-shot or zero-shot learning, respectively. — [Melanie](https://www.linkedin.com/in/melanierbeck/)
- [Language Models as Knowledge Bases?](https://www.aclweb.org/anthology/D19-1250.pdf)
  \*\*\*\*Whilst learning linguistic knowledge, pretrained bidirectional language models like BERT may also be storing relational knowledge present in the training data, and may be able to answer queries structured as "fill-in-the-blank" cloze statements (similar to masked language training objective). This paper brings attention to how knowledge encoded in the weights of these models can be leveraged as knowledge bases. — [Victor](https://twitter.com/vykthur)
- [Statistical Rethinking](https://www.youtube.com/watch?v=4WVelCswXo4) (recommended watching)
  My colleagues will tell you how tiresome I am about probabilistic methods. Recently, I've been enjoying Richard McElreath's Statistical Rethinking lecture series, and now wish this is how I had first encountered Bayesian statistics. I highly recommend it, even to those who are as nerdy about Bayesian methods as I am. — [Chris](https://twitter.com/_cjwallace)
- [Image-GPT](https://openai.com/blog/image-gpt/)
  Transformer models like BERT, RoBERT, GPT and their variants have made enormous progress in natural language tasks. These models have been trained on large corpus of data and are utilized for many tasks like predicting the next word in some given text. In a similar vein, an image-based transformer model can predict the next pixel. This could be a promising route to learning unsupervised image representations (similar to word representations), which in turn could be utilized for image completion tasks or applications involving learning from low resolution images. - [Nisha](https://twitter.com/NishaMuktewar)
- [Towards Ecologically Valid Research on Language User Interfaces](https://arxiv.org/abs/2007.14435)
  Why have we not seen an explosion in Language User Interfaces (Siri is a well known example of a personal assistant, others include assistants for business analysts and visually impaired) given the breakthroughs in NLP? This paper suggests that the data collection process is to blame, and offers an ideal methodology. In the earlier days of LUI research, researchers focused on collecting data that closely simulated the LUI's anticipated use-case. These days, due to the massive data requirements of ML approaches used to build LUIs, tasks have become artificial and have sacrificed "ecological validity". Read to find out five common ways current benchmarks deviate from the ideal research methodology. — [Shioulin](https://www.linkedin.com/in/shioulinsam/)
- [Kid Pix 1.0](https://archive.org/details/KID_PIX_DOS)
  Kid Pix, which I used to use in computer lab in elementary school, is playable via the Internet Archive’s emulator. Looking back at it, I’m impressed by how whimsical and playful many of the effects and icons are — something we could use more of in modern software design. — [Grant](https://twitter.com/grantcuster)

---

## Events

### Conference: [Deep Learning for Anomaly Detection](https://odsc.com/speakers/deep-learning-for-anomaly-detection/)

Nisha Muktewar will be speaking about [our research](https://ff12.fastforwardlabs.com/) on Deep Learning for Anomaly Detection at [Open Data Science Conference Europe](https://odsc.com/europe/) on September 17th.
