---
date: "2016-07-08T17:29:52Z"
preview_image: http://68.media.tumblr.com/bbb5c0978c75c9e2e36e04e770b6ccd5/tumblr_inline_oa065reL0V1ta78fg_540.png
redirect_from:
- /post/147100449348/what-we-liked-at-ainow
tags:
- artificial intelligence
- policy
- white house
title: What We Liked at AINow
aliases:
  - /2016/07/08/what-we-liked-at-ainow.html
---

<figure data-orig-width="605" data-orig-height="320" class="tmblr-full"><img src="http://68.media.tumblr.com/bbb5c0978c75c9e2e36e04e770b6ccd5/tumblr_inline_oa065reL0V1ta78fg_540.png" alt="image" data-orig-width="605" data-orig-height="320"/></figure><p>Over the past two months, the White House <a href="https://www.whitehouse.gov/blog/2016/05/03/preparing-future-artificial-intelligence">ran a series of workshops</a> geared to “prepare for the future of artificial intelligence.” At each session, technologists, academics, policy makers, and social scientists discussed social and economic issues stemming from data technologies, which will feed into the development of a public report later this year (likely similar to the <a href="https://www.ftc.gov/system/files/documents/reports/big-data-tool-inclusion-or-exclusion-understanding-issues/160106big-data-rpt.pdf">FTC’s January report</a> on the social impact of big data). </p><p>The <a href="https://artificialintelligencenow.com/schedule/conference">last session</a> took place yesterday in NYC. Mike Williams, Friederike Schuur, and Miriam Shiffman represented Fast Forward Labs at the event, and reported these highlights: </p><ul><li><a href="https://artificialintelligencenow.com/schedule/conference/speaker/roy-l-austin">Roy Austin</a> of the White House Policy Council underscored that the government has a long way to go to improve data collection practices. To illustrate his point, he mentioned that the 2014 data on hate crimes only contained one hate crime incident in Alabama for the entire year. Before reaping the benefits of analytics and algorithms, therefore, the government has to update systems to collect data, being mindful not to bias minority and racial groups. </li><li>Deep learning icon Yann LeCun said unsupervised learning is the next frontier for the research community. Yoshua Bengio (and many others) expressed the same in <a href="http://www.oreilly.com/data/free/future-of-machine-intelligence.csp?intcmp=il-data-free-lp-lgen_new_site_future_of_machine_intelligence_text_cta">his interview for a recent O’Reilly publication</a>. Indeed, supervised learning, where systems take in labeled training data to learn to perform tasks <a href="http://pictograph.us">like identify objects in pictures</a>, is currently the state of the art in many machine learning techniques. Getting useful labeled data can take time, requiring lots of manpower behind the curtain to get systems working.</li><li><a href="https://artificialintelligencenow.com/schedule/conference/speaker/cynthia-braezeal">Cynthia Braezeal</a> from the MIT Media Lab commented that machine intelligence is different from human intelligence. As such, use should be focused on how to pair to complementary but different skills to improve outputs: we should accept the oddness of machine intelligence instead of aiming to mimic human intelligence. Eric Colson from Stitch Fix thinks of the <a href="http://blog.fastforwardlabs.com/2016/05/25/human-machine-algorithms-interview-with-eric.html">human-machine partnerships</a> in their recommendation algorithms similarly. </li><li>Harvard Professor <a href="http://dataprivacylab.org/people/sweeney/">Latanya Sweeney</a>, who’s done extensive work on data privacy, discussed how easy it can be to identify individuals from fragments on health data. She commented that “computers aren’t evil” in themselves, and called for efforts to “scientifically harmonize computers with society.”</li></ul><p>As always, participants mentioned the syncopation between innovation and regulation, the fact that Silicon Valley and Washington operate at different frequencies. Knowing policies and regulations can’t keep up, what ethics should we espouse as we build products? If we anticipate potential negative social impacts, does that stymy creativity or pollute research? What is the most productive way for us to address potential risks while still fostering and promoting creativity?</p><p>The debate is open. It’s ours to shape.</p><p>- Kathryn</p>
