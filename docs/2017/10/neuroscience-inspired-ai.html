<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <title>Neuroscience-inspired AI</title>
    <link rel="stylesheet" type="text/css" href="/style.css" />
  </head>
  <body>
      <main id="main">
        
<div class="container">
<div class="spacer"></div>
<a href="https://www.cloudera.com/products/fast-forward-labs-research.html">
  <img style="height: 0.8rem;" src="/images/cloudera-fast-forward-logo.png" />
</a>
<div class="spacer"></div>
<div>
  <h3 style="margin: 0"><a href="/">Blog</a></h3>
</div>
<div class="post">
  <div class="spacer"></div>
  <h5 style="margin-bottom: 4px;">
    <span>Oct 26, 2017</span> &middot;
    <span style="text-transform: capitalize;">
      
      newsletter
      
    </span>
  </h5>
  <h1>Neuroscience-inspired AI</h1>
  <p>Pioneers in artificial intelligence (AI) have worked across multiple related fields, including computer science, AI, neuroscience, and psychology - but as each of these areas of research have grown in complexity and disciplinary boundaries have solidified, collaboration has become less commonplace. In <a href="https://www.ncbi.nlm.nih.gov/pubmed/28728020"><em>Neuroscience-Inspired Artificial Intelligence</em></a>, the co-founder of Google DeepMind <a href="https://en.wikipedia.org/wiki/Demis_Hassabis">Demis Hassabis</a>, alongside other renowned neuroscientists, argues to revive collaborative efforts.</p>
<p>The (human) brain is a living case-in-point that human-level general AI is possible, but building it is a daunting task. The search space is vast and sparsely populated; biological intelligence provides a guide. Neuroscience can validate AI techniques that exist already: if known algorithms are found to be implemented in the brain, they are likely an integral component of general intelligence systems.</p>
<p>Neuroscience also provides a rich source of inspiration for new types of algorithms and architectures; a set of recent papers (<a href="https://deepmind.com/blog/hippocampus-predictive-map/">Stachenfeld et al.</a>, <a href="https://www.ncbi.nlm.nih.gov/pubmed/27313047">Constantinescou at al.</a>) suggests there are types of data representations sufficiently flexible and abstract as to support the remarkable human capacity of generalizing experiences to novel situations — a tough nut many AI researchers are looking to crack (i.e., <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer</a> / <a href="https://en.wikipedia.org/wiki/One-shot_learning">one-</a> or <a href="https://www.quora.com/What-is-zero-shot-learning">zero-shot</a> learning) — and that a mechanism for constructing these (abstract) representations from sensory experience exists.</p>
<h3 id="a-nobel-prized-story-of-the-hippocampus">A Nobel-prized story of the hippocampus</h3>
<p>It&rsquo;s Nobel season, and in 2014, Edvard and May-Britt Moser, alongside John O&rsquo;Keefe, were <a href="https://www.nobelprize.org/nobel_prizes/medicine/laureates/2014/press.html">awarded</a> the Nobel Prize in Physiology or Medicine for their discovery of a set of cells in the hippocampus (a brain structure deep inside the mammalian brain) thought to help us orient and navigate in space. Drivers of black-cabs in London, required to memorize some 25,000 streets and thousands of landmarks, for example, have a <a href="https://www.wired.com/2011/12/london-taxi-driver-memory/">larger than usual hippocampus</a>; their brains have adapted to the unique demands of their jobs.</p>
<p>Stachenfeld and colleagues show that the hippocampus does more than encode locations in space. Instead, it encodes &ldquo;<a href="https://www.nature.com/articles/s41562-017-0180-8">successor representations</a>,&rdquo; information about likely <em>future</em> locations given your current location.</p>
<h3 id="successor-representations-in-decision-making">Successor representations in decision making</h3>
<p>Think about how you choose your route to work (or the next move in a game of chess or Go). You need to estimate the likely future reward of your decision in order to make a smart decision now. This is tricky, because the number of possible scenarios increases exponentially, the further you peek into the future. <a href="https://deepmind.com/blog/alphago-zero-learning-scratch/">AlphaGo Zero</a>, the Go playing champ built by Google DeepMind, uses advanced tree search (<a href="http://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/">Monte Carlo tree search</a>) to simulate the future in order to make smart decisions in the now.</p>
<p>Rats - capable of strategic, reward-maximizing decisions - are unlikely to use such computationally expensive methods. Successor representations offer a computationally less expensive yet flexible mechanism. They are a kind of look-up table that contains information about likely future states (e.g., locations) given the current state (i.e., where you <em>will</em> be, given where you are now). Combined with information about (future) reward, successor representations enable reward-maximizing decisions without expensive simulation. They also enable quick adaptation to changes in reward (a novel food source, for example) - while adaptations to changes in space (e.g., a new obstacle) will be slower.</p>
<p>Stachenfeld and colleagues offer empirical evidence for the existence of successor representations in the rat&rsquo;s hippocampus <em>and</em> for the existence of a low-dimensional decomposition of successor representations in the <a href="https://en.wikipedia.org/wiki/Entorhinal_cortex">entorhinal cortex</a> (the main interface between the hippocampus and neocortex). The authors show that these low-dimensional decompositions of the successor representations lend themselves to the discovery of subgoals, a hallmark of efficient planning and <em>the</em> foundation for hierarchical, increasingly abstract representations of tasks required for the generalization of knowledge to novel scenarios.</p>
<p><img src="/images/2017/10/Screen_Shot_2017_10_09_at_9-1507556105313.33" alt=""></p>
<h5 id="comparing-model-predictions-b-to-reality-a-ie-the-firing-rates-of-cells-recorded-in-the-hippocampus-of-a-rat-as-the-rat-is-trained-to-run-in-a-preferred-direction-along-a-narrow-track-initially-symmetric-place-cells-red-begin-to-skew-blue-predicted-in-theory-b-and-demonstrated-in-practice-a">Comparing model predictions (B) to reality (A) (i.e., the firing rates of cells recorded in the hippocampus of a rat). As the rat is trained to run in a preferred direction along a narrow track, initially symmetric place cells (red) begin to skew (blue) predicted in theory (B) and demonstrated in practice (A).</h5>
<h3 id="from-rats-to-humans-from-spatial-navigation-to-abstract-reasoning">From rats to humans, from spatial navigation to abstract reasoning</h3>
<p>This isn&rsquo;t isolated to rats; humans also use these decompositions of successor representations during strategic planning and decision making, as <a href="https://www.ncbi.nlm.nih.gov/pubmed/27313047">Constantinescou and colleagues</a> show. What&rsquo;s more, successor representations and their decompositions are used not only during spatial navigation, but also during <em>abstract</em> reasoning; abstract reasoning capabilities piggyback on representations evolved for spatial reasoning tasks.</p>
<p>Taken together, successor representations and their decompositions provide us with a clue as to how the brain computes abstract representations from sensory inputs that allow us (human and non-human animals) to generalize our experiences to novel situations, thus showing that the collaboration between neuroscience, psychology, and AI could be a very fruitful one indeed.</p>

  <div class="spacer"></div>
  <hr />
</div>
</div>

      </main>
      <div class="container">
        <div style="padding-bottom: 1rem">
          <h2 style="margin-top: 0; margin-bottom: 0px;">About</h2>
          <p style="margin-bottom: 0px;">
            Cloudera Fast Forward is an applied machine learning research group.
          </p>
          <a
            href="https://www.cloudera.com/products/fast-forward-labs-research.html"
            >Cloudera</a
          >&nbsp;
          <a href="http://experiments.fastforwardlabs.com">Experiments</a>&nbsp;
          <a href="https://twitter.com/fastforwardlabs">Twitter</a>
          <p></p>
        </div>
      </div>
  </body>
</html>
