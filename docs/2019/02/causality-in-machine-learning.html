<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <title>Causality in machine learning</title>
    <link rel="stylesheet" type="text/css" href="/style.css" />
  </head>
  <body>
      <main id="main">
        
<div class="container">
<div class="spacer"></div>
<a href="https://www.cloudera.com/products/fast-forward-labs-research.html">
  <img style="height: 0.8rem;" src="/images/cloudera-fast-forward-logo.png" />
</a>
<div class="spacer"></div>
<div>
  <h3 style="margin: 0"><a href="/">Blog</a></h3>
</div>
<div class="post">
  <div class="spacer"></div>
  <h5 style="margin-bottom: 4px;">
    <span>Feb 28, 2019</span> &middot;
    <span style="text-transform: capitalize;">
      
      newsletter
      
    </span>
  </h5>
  <h1>Causality in machine learning</h1>
  <p><a href="https://en.wikipedia.org/wiki/Judea_Pearl">Judea Pearl</a>, the inventor of <a href="https://en.wikipedia.org/wiki/Bayesian_network">Bayesian networks</a>, recently published a book called <em><a href="https://www.amazon.com/dp/B075CR9QBJ/">The Book of Why: The New Science of Cause and Effect</a></em>. The book covers a great many things, including a detailed history of how the fields of causality and statistics have long been at odds, Pearl&rsquo;s own <a href="https://www.inference.vc/untitled/"><em>do-calculus</em></a> framework for teasing causal inferences from observational data, and why (in Pearl&rsquo;s view) the future of AI depends on causality.</p>
<p><img src="/images/editor_uploads/2019-03-12-191909-correlation.png" alt=""></p>
<h5 id="source-correlation-by-randall-munroe-at-xkcdhttpsxkcdcom552">Source: <a href="https://xkcd.com/552/">&ldquo;Correlation&rdquo; by Randall Munroe at XKCD</a></h5>
<p>One of the key points in Pearl&rsquo;s book is that observational data - data collected from real world systems - on its own, can only possibly convey associations between variables. To glean which variables in the data act as causes, and which are effects of those causes, we need something more. The implications are profound. A pharmaceutical company cannot ever tell if a particular drug is an effective treatment for a disease simply by observing the outcomes of patients who have taken that drug. It is impossible for scientists to prove that smoking causes lung cancer from observing outcomes of smokers and non-smokers. And yet, these are both things that we as a society have the capability to do today.</p>
<p>The traditional method for proving cause and effect is called a <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">randomized controlled trial</a>. In a randomized controlled trial, you randomly assign some test subjects to a treatment group and some to a control group. In the case of proving the effectiveness of a drug, patients are randomly assigned to receive the drug or not. By doing this, you can guarantee that the two groups are the same in every possible way, except for the treatment. If you then observe that the outcomes of one group are better than another, you can conclude that the treatment causes the improved outcome.</p>
<p>But randomized controlled trials are expensive, slow, and oftentimes impossible. You cannot ethically force a group of patients to smoke for a lifetime simply for the sake of proving that smoking causes cancer. And indeed, this is precisely the dilemma that made it extremely difficult to prove that smoking causes cancer, a topic Pearl covers in exquisite detail in his book. On top of that, observational data is cheap and plentiful. Is there truly no way to tease causality from observational data?</p>
<p>In a <a href="https://www.youtube.com/watch?v=ynVr_zzUXtw">recent panel on causality</a> from the Machine Learning Summer School in South Africa, Columbia University professor <a href="http://www.cs.columbia.edu/~blei/">David Blei</a> explained that this conundrum is precisely what has motivated him to pursue causality in his research.</p>
<blockquote>
<p>&ldquo;When you sit down and read all the books about causal inference and all the papers about it, it&rsquo;s very theoretical but there&rsquo;s one message that you get, from the historical perspective anyway, which is that causal inference from observational data is impossible . . . To me that seemed silly, that with, say you&rsquo;re a hospital and you have 250 million electronic health records of what medicines people received and what happened to those people. It seemed silly to say that it is impossible to learn, say that Advil helps headaches.&rdquo;</p>
</blockquote>
<p>There are many ways in which causal understanding could improve the fields of machine learning and AI, and the ability to reliably infer causation from observational data is a hot topic. Judea Pearl&rsquo;s do-calculus is primarily a framework for doing just that. Under the right conditions and with some assumptions, causality can be inferred from purely observational data.</p>
<p>A machine learning model that captures causal relationships of data is one way to ensure that the model will generalize to new settings, one of the most difficult aspects of machine learning. A model that associates the rising of the sun with the crow of a rooster may be able to adequately predict when the sun will rise. If the rooster has just crowed, the sun will rise shortly thereafter. This model will not, however, generalize to situations where there is no rooster. It would never predict that the sun will rise because it has never observed such a data point. However, if the model captured the causal relationships between the two, that the sun being about to rise causes the rooster&rsquo;s crow, it would be obvious that the sun will rise even without the rooster.</p>
<p>Causality is also tightly related to fairness in machine learning, <a href="https://blog.fastforwardlabs.com/newsletters/2019-02-06-client.html">a topic we care deeply about</a>. In <em>The Book of Why</em>, Pearl discusses the &ldquo;Berkeley admissions paradox,&rdquo; the story of one statistician&rsquo;s attempt in the 1970s to detect potential discrimination against admitting women at UC Berkeley. Pearl discusses how traditional statistics combined only with observational data can lead to competing conclusions. It is possible to conclude that the university discriminated against women or that they discriminated in favor of women, depending on how you slice the data. Only using the language of causality can we draw correct conclusions.</p>
<p>The role of causality in AI and machine learning is a controversial topic, and Pearl has no problems stoking that controversy in his book. Regardless, <em>The Book of Why</em> has helped revive the topic of causality in the ML and AI communities. In the recent machine learning summer school in South Africa, there were multiple sessions on causality. At the recent <a href="https://fatconference.org/2019/">Fairness, Accountability, and Trust</a> conference there were multiple discussions devoted to causality. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Textbooks on causality</a> are being published and <a href="https://www.glassdoor.com/job-listing/data-scientist-causal-inference-and-experimental-design-marketing-science-rd-facebook-JV_IC1150505_KO0,76_KE77,85.htm?jl=3014078256&amp;ctt=1549578150049">multiple</a> <a href="https://www.glassdoor.com/job-listing/researcher-causality-and-machine-learning-microsoft-JV_IC1150499_KO0,41_KE42,51.htm?jl=3087412884&amp;ctt=1549578042811">jobs</a> asking for causal inference are popping up. Though the immediate future of causality in machine learning is likely (still) limited to randomized controlled trials like A/B testing, the potential to draw causal conclusions from near-unlimited quantities of observational data is too great to ignore. Finally, Pearl argues that cause and effect are the key mechanisms through which humans process the complex world around them, and that we can never reach true <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">artificial general intelligence</a> without equipping machines with notions of cause and effect.</p>

  <div class="spacer"></div>
  <hr />
</div>
</div>

      </main>
      <div class="container">
        <div style="padding-bottom: 1rem">
          <h2 style="margin-top: 0; margin-bottom: 0px;">About</h2>
          <p style="margin-bottom: 0px;">
            Cloudera Fast Forward is an applied machine learning research group.
          </p>
          <a
            href="https://www.cloudera.com/products/fast-forward-labs-research.html"
            >Cloudera</a
          >&nbsp;
          <a href="http://experiments.fastforwardlabs.com">Experiments</a>&nbsp;
          <a href="https://twitter.com/fastforwardlabs">Twitter</a>
          <p></p>
        </div>
      </div>
  </body>
</html>
