<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deep learning on Blog</title>
    <link>http://test-blog.fastforwardlabs.com/tags/deep-learning.html</link>
    <description>Recent content in deep learning on Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Aug 2016 17:43:24 +0000</lastBuildDate>
    
	<atom:link href="http://test-blog.fastforwardlabs.com/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring Deep Learning on Satellite Data</title>
      <link>http://test-blog.fastforwardlabs.com/2016/08/26/exploring-deep-learning-on-satellite-data.html</link>
      <pubDate>Fri, 26 Aug 2016 17:43:24 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/08/26/exploring-deep-learning-on-satellite-data.html</guid>
      <description>This is a guest post featuring a project Patrick Doupe, now a Senior Data Analyst at Icahn School of Medicine at Mount Sinai, completed as a fellow in the Insight Data Science program. In our partnership with Insight, we occassionally advise fellows on month-long projects and how to build a career in data science. </description>
    </item>
    
    <item>
      <title>New TensorFlow Code for Text Summarization</title>
      <link>http://test-blog.fastforwardlabs.com/2016/08/25/new-tensorflow-code-for-text-summarization.html</link>
      <pubDate>Thu, 25 Aug 2016 17:24:14 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/08/25/new-tensorflow-code-for-text-summarization.html</guid>
      <description></description>
    </item>
    
    <item>
      <title>Next Economics: Interview with Jimi Crawford</title>
      <link>http://test-blog.fastforwardlabs.com/2016/08/24/next-economics-interview-with-jimi-crawford.html</link>
      <pubDate>Wed, 24 Aug 2016 16:18:12 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/08/24/next-economics-interview-with-jimi-crawford.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;h5 id=&#34;building-shadows-as-proxies-for-construction-rates-in-shanghai-photos-courtesy-of-orbital-insightdigital-globe&#34;&gt;Building shadows as proxies for construction rates in Shanghai. Photos courtesy of Orbital Insight/Digital Globe.&lt;/h5&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>Under the Hood of the Variational Autoencoder (in Prose and Code)</title>
      <link>http://test-blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in-prose-and-code.html</link>
      <pubDate>Mon, 22 Aug 2016 18:02:08 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in-prose-and-code.html</guid>
      <description>&lt;h5 id=&#34;the-a-hrefhttpsarxivorgabs13126114variationala-a-hrefhttpsarxivorgabs14014082autoencodera-vae-neatly-synthesizes-unsupervised-deep-learning-and-variational-bayesian-methods-into-one-sleek-package-in-a-hrefhttpblogfastforwardlabscom20160812introducing-variational-autoencoders-in-prose-andhtmlpart-ia-of-this-series-we-introduced-the-theory-and-intuition-behind-the-vae-an-exciting-development-in-machine-learning-for-combined-generative-modeling-and-inferencea-hrefhttpshakirmcomslidesdlsummerschool_aug2016_compresspdfmachines-that-imagine-and-reasona&#34;&gt;The &lt;!-- raw HTML omitted --&gt;Variational&lt;!-- raw HTML omitted --&gt; &lt;!-- raw HTML omitted --&gt;Autoencoder&lt;!-- raw HTML omitted --&gt; (VAE) neatly synthesizes unsupervised deep learning and variational Bayesian methods into one sleek package. In &lt;!-- raw HTML omitted --&gt;Part I&lt;!-- raw HTML omitted --&gt; of this series, we introduced the theory and intuition behind the VAE, an exciting development in machine learning for combined generative modeling and inference—&lt;!-- raw HTML omitted --&gt;“machines that imagine and reason.”&lt;!-- raw HTML omitted --&gt;&lt;/h5&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>Introducing Variational Autoencoders (in Prose and Code)</title>
      <link>http://test-blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and-code.html</link>
      <pubDate>Fri, 12 Aug 2016 17:09:50 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and-code.html</guid>
      <description>import tensorflow as tf from tensorflow.examples.tutorials.mnist import input_data import vae # this is our model - to be explored in the next post IMG_DIM = 28 ARCHITECTURE = [IMG_DIM**2, # 784 pixels 500, 500, # intermediate encoding 50] # latent space dims # (and symmetrically back out again) HYPERPARAMS = { &amp;#34;batch_size&amp;#34;: 128, &amp;#34;learning_rate&amp;#34;: 1E-3, &amp;#34;dropout&amp;#34;: 0.9, &amp;#34;lambda_l2_reg&amp;#34;: 1E-5, &amp;#34;nonlinearity&amp;#34;: tf.nn.elu, &amp;#34;squashing&amp;#34;: tf.nn.sigmoid } mnist = input_data.read_data_sets(&amp;#34;mnist_data&amp;#34;) v = vae.VAE(ARCHITECTURE, HYPERPARAMS) v.</description>
    </item>
    
    <item>
      <title>Machine Listening: Interview with Juan Pablo Bello</title>
      <link>http://test-blog.fastforwardlabs.com/2016/06/10/machine-listening-interview-with-juan-pablo-bello.html</link>
      <pubDate>Fri, 10 Jun 2016 14:23:11 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/06/10/machine-listening-interview-with-juan-pablo-bello.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;h5 id=&#34;a-probabilistic-latent-component-analysis-of-a-pitch-class-sequence-for-the-beatles-good-day-sunshine-the-top-layer-shows-the-original-representation-time-vs-pitch-class-subsequent-layers-show-latent-components&#34;&gt;A probabilistic latent component analysis of a pitch class sequence for The Beatles’ Good Day Sunshine. The top layer shows the original representation (time vs pitch class). Subsequent layers show latent components.&lt;/h5&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>&#34;Hello world&#34; in Keras (or, Scikit-learn versus Keras)</title>
      <link>http://test-blog.fastforwardlabs.com/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html</link>
      <pubDate>Wed, 24 Feb 2016 18:58:10 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html</guid>
      <description>&amp;gt;&amp;gt;&amp;gt; %matplotlib inline &amp;gt;&amp;gt;&amp;gt; import seaborn as sns &amp;gt;&amp;gt;&amp;gt; import numpy as np &amp;gt;&amp;gt;&amp;gt; from sklearn.cross_validation import train_test_split &amp;gt;&amp;gt;&amp;gt; from sklearn.linear_model import LogisticRegressionCV &amp;gt;&amp;gt;&amp;gt; from keras.models import Sequential &amp;gt;&amp;gt;&amp;gt; from keras.layers.core import Dense, Activation &amp;gt;&amp;gt;&amp;gt; from keras.utils import np_utils &amp;gt;&amp;gt;&amp;gt; iris = sns.load_dataset(&amp;#34;iris&amp;#34;) &amp;gt;&amp;gt;&amp;gt; iris.head() &amp;gt;&amp;gt;&amp;gt; sns.pairplot(iris, hue=&amp;#39;species&amp;#39;) &amp;gt;&amp;gt;&amp;gt; X = iris.values[:, 0:4] &amp;gt;&amp;gt;&amp;gt; y = iris.values[:, 4] &amp;gt;&amp;gt;&amp;gt; train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.5, random_state=0) &amp;gt;&amp;gt;&amp;gt; lr = LogisticRegressionCV() &amp;gt;&amp;gt;&amp;gt; lr.</description>
    </item>
    
    <item>
      <title>NeuralTalk with Kyle McDonald</title>
      <link>http://test-blog.fastforwardlabs.com/2016/02/18/neuraltalk-with-kyle-mcdonald.html</link>
      <pubDate>Thu, 18 Feb 2016 15:09:51 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/02/18/neuraltalk-with-kyle-mcdonald.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;h5 id=&#34;image-from-a-hrefhttpsvimeocom90547410social-soula-an-immersive-experience-of-being-inside-a-social-media-stream-by-a-hrefhttplauren-mccarthycomlauren-mccarthya-and-kyle-mcdonald&#34;&gt;Image from &lt;!-- raw HTML omitted --&gt;Social Soul&lt;!-- raw HTML omitted --&gt;, an immersive experience of being inside a social media stream, by &lt;!-- raw HTML omitted --&gt;Lauren McCarthy&lt;!-- raw HTML omitted --&gt; and Kyle McDonald&lt;/h5&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>Machines and Metaphors</title>
      <link>http://test-blog.fastforwardlabs.com/2016/02/16/machines-and-metaphors.html</link>
      <pubDate>Tue, 16 Feb 2016 16:35:11 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2016/02/16/machines-and-metaphors.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
&lt;h5 id=&#34;this-is-a-guest-post-by-a-hrefhttpwwwgenekogancomgene-kogana-an-artist-and-programmer-who-applies-emerging-technology-into-artistic-and-expressive-contexts-and-teaches-courses-and-workshops-on-topics-related-to-code-and-art&#34;&gt;This is a guest post by &lt;!-- raw HTML omitted --&gt;Gene Kogan&lt;!-- raw HTML omitted --&gt;, an artist and programmer who applies emerging technology into artistic and expressive contexts, and teaches courses and workshops on topics related to code and art.&lt;/h5&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>Fashion Goes Deep: Data Science at Lyst</title>
      <link>http://test-blog.fastforwardlabs.com/2015/12/09/fashion-goes-deep-data-science-at-lyst.html</link>
      <pubDate>Wed, 09 Dec 2015 17:44:00 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/12/09/fashion-goes-deep-data-science-at-lyst.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>When Dog Is Enough: Using Hypernyms To Improve Neural Network Predictions</title>
      <link>http://test-blog.fastforwardlabs.com/2015/11/17/when-dog-is-enough-using-hypernyms-to-improve-neural-network-predictions.html</link>
      <pubDate>Tue, 17 Nov 2015 16:35:14 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/11/17/when-dog-is-enough-using-hypernyms-to-improve-neural-network-predictions.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>Hello Deep Learning</title>
      <link>http://test-blog.fastforwardlabs.com/2015/10/26/hello-deep-learning.html</link>
      <pubDate>Mon, 26 Oct 2015 16:20:07 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/10/26/hello-deep-learning.html</guid>
      <description></description>
    </item>
    
    <item>
      <title>How do neural networks learn?</title>
      <link>http://test-blog.fastforwardlabs.com/2015/09/24/how-do-neural-networks-learn.html</link>
      <pubDate>Thu, 24 Sep 2015 18:56:09 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/09/24/how-do-neural-networks-learn.html</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fast Forward Labs Interviews Clarifai about Deep Learning</title>
      <link>http://test-blog.fastforwardlabs.com/2015/09/22/fast-forward-labs-interviews-clarifai-about-deep-learning.html</link>
      <pubDate>Tue, 22 Sep 2015 18:58:45 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/09/22/fast-forward-labs-interviews-clarifai-about-deep-learning.html</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pictograph: Unlock Your Images</title>
      <link>http://test-blog.fastforwardlabs.com/2015/09/15/pictograph-unlock-your-images.html</link>
      <pubDate>Tue, 15 Sep 2015 19:16:19 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/09/15/pictograph-unlock-your-images.html</guid>
      <description></description>
    </item>
    
    <item>
      <title>D’Alembert’s Deep Dream: Bees and Nonlinear Transformations</title>
      <link>http://test-blog.fastforwardlabs.com/2015/09/02/dalemberts-deep-dream-bees-and-nonlinear-transformations.html</link>
      <pubDate>Wed, 02 Sep 2015 14:08:33 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/09/02/dalemberts-deep-dream-bees-and-nonlinear-transformations.html</guid>
      <description>&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>Why Now? Some Preconditions for Technology Innovations</title>
      <link>http://test-blog.fastforwardlabs.com/2015/08/14/why-now-some-preconditions-for-technology-innovations.html</link>
      <pubDate>Fri, 14 Aug 2015 18:57:31 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/08/14/why-now-some-preconditions-for-technology-innovations.html</guid>
      <description>This is French how painter Nicolas Poussin represents Cedalion providing sight to the blind Orion, a mythological pair associated with each generation’s progress over its predecessors. </description>
    </item>
    
    <item>
      <title>On Stirling Engines and Orchids: A Prelude to Deep Learning</title>
      <link>http://test-blog.fastforwardlabs.com/2015/08/07/on-stirling-engines-and-orchids-a-prelude-to-deep-learning.html</link>
      <pubDate>Fri, 07 Aug 2015 19:08:04 +0000</pubDate>
      
      <guid>http://test-blog.fastforwardlabs.com/2015/08/07/on-stirling-engines-and-orchids-a-prelude-to-deep-learning.html</guid>
      <description></description>
    </item>
    
  </channel>
</rss>